features. The focus at this point is on describing the data and their relationships,
rather than on specifying physical storage details.
In terms of the relational model, the conceptual-design process involves decisions on what attributes we want to capture in the database and how to group
these attributes to form the various tables. The “what” part is basically a business
decision, and we shall not discuss it further in this text. The “how” part is mainly a
computer-science problem. There are principally two ways to tackle the problem.
The first one is to use the entity-relationship model (Section 1.6.3); the other is
to employ a set of algorithms (collectively known as normalization) that takes as
input the set of all attributes and generates a set of tables (Section 1.6.4).
A fully developed conceptual schema indicates the functional requirements
of the enterprise. In a specification of functional requirements, users describe the
kinds of operations (or transactions) that will be performed on the data. Example
operations include modifying or updating data, searching for and retrieving
specific data, and deleting data. At this stage of conceptual design, the designer
can review the schema to ensure it meets functional requirements.
The process of moving from an abstract data model to the implementation of
the database proceeds in two final design phases. In the logical-design phase, the
designer maps the high-level conceptual schema onto the implementation data
model of the database system that will be used. The designer uses the resulting
system-specific database schema in the subsequent physical-design phase, in
which the physical features of the database are specified. These features include
the form of file organization and the internal storage structures; they are discussed
in Chapter 10.
1.6.2 Database Design for a University Organization
To illustrate the design process, let us examine how a database for a university
could be designed. The initial specification of user requirements may be based
on interviews with the database users, and on the designer’s own analysis of
the organization. The description that arises from this design phase serves as the
basis for specifying the conceptual structure of the database. Here are the major
characteristics of the university.
• The university is organized into departments. Each department is identified
by a unique name (dept name), is located in a particular building, and has a
budget.
• Each department has a list of courses it offers. Each course has associated with
it a course id, title, dept name, and credits, and may also have have associated
prerequisites.
• Instructors are identified by their unique ID. Each instructor has name, associated department (dept name), and salary.
• Students are identified by their unique ID. Each student has a name, an associated major department (dept name), and tot cred (total credit hours the student
earned thus far).
1.6 Database Design 17
• The university maintains a list of classrooms, specifying the name of the
building, room number, and room capacity.
• The university maintains a list of all classes (sections) taught. Each section is
identified by a course id, sec id, year, and semester, and has associated with it
a semester, year, building, room number, and time slot id (the time slot when the
class meets).
• The department has a list of teaching assignments specifying, for each instructor, the sections the instructor is teaching.
• The university has a list of all student course registrations, specifying, for
each student, the courses and the associated sections that the student has
taken (registered for).
A real university database would be much more complex than the preceding
design. However we use this simplified model to help you understand conceptual
ideas without getting lost in details of a complex design.
1.6.3 The Entity-Relationship Model
The entity-relationship (E-R) data model uses a collection of basic objects, called
entities, and relationships among these objects. An entity is a “thing” or “object”
in the real world that is distinguishable from other objects. For example, each
person is an entity, and bank accounts can be considered as entities.
Entities are described in a database by a set of attributes. For example, the
attributes dept name, building, and budget may describe one particular department
in a university, and they form attributes of the department entity set. Similarly,
attributes ID, name, and salary may describe an instructor entity.2
The extra attribute ID is used to identify an instructor uniquely (since it may
be possible to have two instructors with the same name and the same salary).
A unique instructor identifier must be assigned to each instructor. In the United
States, many organizations use the social-security number of a person (a unique
number the U.S. government assigns to every person in the United States) as a
unique identifier.
A relationship is an association among several entities. For example, a member
relationship associates an instructor with her department. The set of all entities
of the same type and the set of all relationships of the same type are termed an
entity set and relationship set, respectively.
The overall logical structure (schema) of a database can be expressed graphically by an entity-relationship (E-R) diagram. There are several ways in which to
draw these diagrams. One of the most popular is to use the Unified Modeling
Language (UML). In the notation we use, which is based on UML, an E-R diagram
is represented as follows:
2The astute reader will notice that we dropped the attribute dept name from the set of attributes describing the instructor
entity set; this is not an error. In Chapter 7 we shall provide a detailed explanation of why this is the case.
18 Chapter 1 Introduction
instructor
ID
name
salary
department
dept_name
building
budget
member
Figure 1.3 A sample E-R diagram.
• Entity sets are represented by a rectangular box with the entity set name in
the header and the attributes listed below it.
• Relationship sets are represented by a diamond connecting a pair of related
entity sets. The name of the relationship is placed inside the diamond.
As an illustration, consider part of a university database consisting of instructors and the departments with which they are associated. Figure 1.3 shows the
corresponding E-R diagram. The E-R diagram indicates that there are two entity
sets, instructor and department, with attributes as outlined earlier. The diagram
also shows a relationship member between instructor and department.
In addition to entities and relationships, the E-R model represents certain
constraints to which the contents of a database must conform. One important
constraint is mapping cardinalities, which express the number of entities to
which another entity can be associated via a relationship set. For example, if each
instructor must be associated with only a single department, the E-R model can
express that constraint.
The entity-relationship model is widely used in database design, and Chapter
7 explores it in detail.
1.6.4 Normalization
Another method for designing a relational database is to use a process commonly
known as normalization. The goal is to generate a set of relation schemas that
allows us to store information without unnecessary redundancy, yet also allows
us to retrieve information easily. The approach is to design schemas that are in
an appropriate normal form. To determine whether a relation schema is in one of
the desirable normal forms, we need additional information about the real-world
enterprise that we are modeling with the database. The most common approach
is to use functional dependencies, which we cover in Section 8.4.
To understand the need for normalization, let us look at what can go wrong
in a bad database design. Among the undesirable properties that a bad design
may have are:
• Repetition of information
• Inability to represent certain information
1.6 Database Design 19
ID name salary dept name building budget
22222 Einstein 95000 Physics Watson 70000
12121 Wu 90000 Finance Painter 120000
32343 El Said 60000 History Painter 50000
45565 Katz 75000 Comp. Sci. Taylor 100000
98345 Kim 80000 Elec. Eng. Taylor 85000
76766 Crick 72000 Biology Watson 90000
10101 Srinivasan 65000 Comp. Sci. Taylor 100000
58583 Califieri 62000 History Painter 50000
83821 Brandt 92000 Comp. Sci. Taylor 100000
15151 Mozart 40000 Music Packard 80000
33456 Gold 87000 Physics Watson 70000
76543 Singh 80000 Finance Painter 120000
Figure 1.4 The faculty table.
We shall discuss these problems with the help of a modified database design for
our university example.
Suppose that instead of having the two separate tables instructor and department, we have a single table, faculty, that combines the information from the two
tables (as shown in Figure 1.4). Notice that there are two rows in faculty that
contain repeated information about the History department, specifically, that
department’s building and budget. The repetition of information in our alternative design is undesirable. Repeating information wastes space. Furthermore, it
complicates updating the database. Suppose that we wish to change the budget
amount of the History department from $50,000 to $46,800. This change must
be reflected in the two rows; contrast this with the original design, where this
requires an update to only a single row. Thus, updates are more costly under the
alternative design than under the original design. When we perform the update
in the alternative database, we must ensure that every tuple pertaining to the History department is updated, or else our database will show two different budget
values for the History department.
Now, let us shift our attention to the issue of “inability to represent certain
information.” Suppose we are creating a new department in the university. In the
alternative design above, we cannot represent directly the information concerning
a department (dept name, building, budget) unless that department has at least one
instructor at the university. This is because rows in the faculty table require
values for ID, name, and salary. This means that we cannot record information
about the newly created department until the first instructor is hired for the new
department.
One solution to this problem is to introduce null values. The null value
indicates that the value does not exist (or is not known). An unknown value
may be either missing (the value does exist, but we do not have that information)
or not known (we do not know whether or not the value actually exists). As we
20 Chapter 1 Introduction
shall see later, null values are difficult to handle, and it is preferable not to resort
to them. If we are not willing to deal with null values, then we can create a
particular item of department information only when the department has at least
one instructor associated with the department. Furthermore, we would have
to delete this information when the last instructor in the department departs.
Clearly, this situation is undesirable, since, under our original database design,
the department information would be available regardless of whether or not
there is an instructor associated with the department, and without resorting to
null values.
An extensive theory of normalization has been developed that helps formally
define what database designs are undesirable, and how to obtain desirable designs. Chapter 8 covers relational-database design, including normalization.
1.7 Data Storage and Querying
A database system is partitioned into modules that deal with each of the responsibilities of the overall system. The functional components of a database
system can be broadly divided into the storage manager and the query processor
components.
The storage manager is important because databases typically require a large
amount of storage space. Corporate databases range in size from hundreds of
gigabytes to, for the largest databases, terabytes of data. A gigabyte is approximately 1000 megabytes (actually 1024) (1 billion bytes), and a terabyte is 1 million
megabytes (1 trillion bytes). Since the main memory of computers cannot store
this much information, the information is stored on disks. Data are moved between disk storage and main memory as needed. Since the movement of data
to and from disk is slow relative to the speed of the central processing unit, it is
imperative that the database system structure the data so as to minimize the need
to move data between disk and main memory.
The query processor is important because it helps the database system to
simplify and facilitate access to data. The query processor allows database users
to obtain good performance while being able to work at the view level and not be
burdened with understanding the physical-level details of the implementation of
the system. It is the job of the database system to translate updates and queries
written in a nonprocedural language, at the logical level, into an efficient sequence
of operations at the physical level.
1.7.1 Storage Manager
The storage manager is the component of a database system that provides the
interface between the low-level data stored in the database and the application
programs and queries submitted to the system. The storage manager is responsible for the interaction with the file manager. The raw data are stored on the
disk using the file system provided by the operating system. The storage manager translates the various DML statements into low-level file-system commands.
1.7 Data Storage and Querying 21
Thus, the storage manager is responsible for storing, retrieving, and updating
data in the database.
The storage manager components include:
• Authorization and integrity manager, which tests for the satisfaction of
integrity constraints and checks the authority of users to access data.
• Transaction manager, which ensures that the database remains in a consistent (correct) state despite system failures, and that concurrent transaction
executions proceed without conflicting.
• File manager, which manages the allocation of space on disk storage and the
data structures used to represent information stored on disk.
• Buffer manager, which is responsible for fetching data from disk storage into
main memory, and deciding what data to cache in main memory. The buffer
manager is a critical part of the database system, since it enables the database
to handle data sizes that are much larger than the size of main memory.
The storage manager implements several data structures as part of the physical system implementation:
• Data files, which store the database itself.
• Data dictionary, which stores metadata about the structure of the database,
in particular the schema of the database.
• Indices, which can provide fast access to data items. Like the index in this
textbook, a database index provides pointers to those data items that hold a
particular value. For example, we could use an index to find the instructor
record with a particular ID, or all instructor records with a particular name.
Hashing is an alternative to indexing that is faster in some but not all cases.
We discuss storage media, file structures, and buffer management in Chapter 10.
Methods of accessing data efficiently via indexing or hashing are discussed in
Chapter 11.
1.7.2 The Query Processor
The query processor components include:
• DDL interpreter, which interprets DDL statements and records the definitions
in the data dictionary.
• DML compiler, which translates DML statements in a query language into an
evaluation plan consisting of low-level instructions that the query evaluation
engine understands.
22 Chapter 1 Introduction
A query can usually be translated into any of a number of alternative
evaluation plans that all give the same result. The DML compiler also performs
query optimization; that is, it picks the lowest cost evaluation plan from
among the alternatives.
• Query evaluation engine, which executes low-level instructions generated
by the DML compiler.
Query evaluation is covered in Chapter 12, while the methods by which the query
optimizer chooses from among the possible evaluation strategies are discussed
in Chapter 13.
1.8 Transaction Management
Often, several operations on the database form a single logical unit of work. An
example is a funds transfer, as in Section 1.2, in which one department account
(say A) is debited and another department account (say B) is credited. Clearly, it
is essential that either both the credit and debit occur, or that neither occur. That
is, the funds transfer must happen in its entirety or not at all. This all-or-none
requirement is called atomicity. In addition, it is essential that the execution of the
funds transfer preserve the consistency of the database. That is, the value of the
sum of the balances of A and B must be preserved. This correctness requirement
is called consistency. Finally, after the successful execution of a funds transfer,
the new values of the balances of accounts A and B must persist, despite the
possibility of system failure. This persistence requirement is called durability.
A transaction is a collection of operations that performs a single logical
function in a database application. Each transaction is a unit of both atomicity
and consistency. Thus, we require that transactions do not violate any databaseconsistency constraints. That is, if the database was consistent when a transaction
started, the database must be consistent when the transaction successfully terminates. However, during the execution of a transaction, it may be necessary
temporarily to allow inconsistency, since either the debit of A or the credit of B
must be done before the other. This temporary inconsistency, although necessary,
may lead to difficulty if a failure occurs.
It is the programmer’s responsibility to define properly the various transactions, so that each preserves the consistency of the database. For example, the
transaction to transfer funds from the account of department A to the account of
department B could be defined to be composed of two separate programs: one
that debits account A, and another that credits account B. The execution of these
two programs one after the other will indeed preserve consistency. However, each
program by itself does not transform the database from a consistent state to a new
consistent state. Thus, those programs are not transactions.
Ensuring the atomicity and durability properties is the responsibility of the
database system itself—specifically, of the recovery manager. In the absence of
failures, all transactions complete successfully, and atomicity is achieved easily.
1.9 Database Architecture 23
However, because of various types of failure, a transaction may not always complete its execution successfully. If we are to ensure the atomicity property, a failed
transaction must have no effect on the state of the database. Thus, the database
must be restored to the state in which it was before the transaction in question
started executing. The database system must therefore perform failure recovery,
that is, detect system failures and restore the database to the state that existed
prior to the occurrence of the failure.
Finally, when several transactions update the database concurrently, the consistency of data may no longer be preserved, even though each individual transaction is correct. It is the responsibility of the concurrency-control manager to control the interaction among the concurrent transactions, to ensure the consistency
of the database. The transaction manager consists of the concurrency-control
manager and the recovery manager.
The basic concepts of transaction processing are covered in Chapter 14. The
management of concurrent transactions is covered in Chapter 15. Chapter 16
covers failure recovery in detail.
The concept of a transaction has been applied broadly in database systems
and applications. While the initial use of transactions was in financial applications, the concept is now used in real-time applications in telecommunication, as
well as in the management of long-duration activities such as product design or
administrative workflows. These broader applications of the transaction concept
are discussed in Chapter 26.
1.9 Database Architecture
We are now in a position to provide a single picture (Figure 1.5) of the various
components of a database system and the connections among them.
The architecture of a database system is greatly influenced by the underlying
computer system on which the database system runs. Database systems can be
centralized, or client-server, where one server machine executes work on behalf
of multiple client machines. Database systems can also be designed to exploit parallel computer architectures. Distributed databases span multiple geographically
separated machines.
In Chapter 17 we cover the general structure of modern computer systems.
Chapter 18 describes how various actions of a database, in particular query processing, can be implemented to exploit parallel processing. Chapter 19 presents a
number of issues that arise in a distributed database, and describes how to deal
with each issue. The issues include how to store data, how to ensure atomicity of
transactions that execute at multiple sites, how to perform concurrency control,
and how to provide high availability in the presence of failures. Distributed query
processing and directory systems are also described in this chapter.
Most users of a database system today are not present at the site of the
database system, but connect to it through a network. We can therefore differentiate between client machines, on which remote database users work, and server
machines, on which the database system runs.
24 Chapter 1 Introduction
Database applications are usually partitioned into two or three parts, as in
Figure 1.6. In a two-tier architecture, the application resides at the client machine,
where it invokes database system functionality at the server machine through
naive users
(tellers, agents,
web users)
query processor
storage manager
disk storage
indices
data statistical data
data dictionary
application
programmers
application
interfaces
application
program
object code
compiler and
linker
buffer manager file manager authorization
and integrity
 manager
transaction
manager
DML compiler
and organizer
query evaluation
engine
DML queries DDL interpreter
application
programs
query
tools
administration
tools
sophisticated
users
(analysts)
database
administrators
use write use use
Figure 1.5 System structure.
1.10 Data Mining and Information Retrieval 25
user
application
database system
network
(a) Two-tier architecture
client
server
user
application client
database system
network
application server
(b) Three-tier architecture
Figure 1.6 Two-tier and three-tier architectures.
query language statements. Application program interface standards like ODBC
and JDBC are used for interaction between the client and the server.
In contrast, in a three-tier architecture, the client machine acts as merely a
front end and does not contain any direct database calls. Instead, the client end
communicates with an application server, usually through a forms interface.
The application server in turn communicates with a database system to access
data. The business logic of the application, which says what actions to carry out
under what conditions, is embedded in the application server, instead of being
distributed across multiple clients. Three-tier applications are more appropriate
for large applications, and for applications that run on the World Wide Web.
1.10 Data Mining and Information Retrieval
The term data mining refers loosely to the process of semiautomatically analyzing
large databases to find useful patterns. Like knowledge discovery in artificial
intelligence (also called machine learning) or statistical analysis, data mining
attempts to discover rules and patterns from data. However, data mining differs
from machine learning and statistics in that it deals with large volumes of data,
stored primarily on disk. That is, data mining deals with “knowledge discovery
in databases.”
Some types of knowledge discovered from a database can be represented by
a set of rules. The following is an example of a rule, stated informally: “Young
women with annual incomes greater than $50,000 are the most likely people to buy
small sports cars.” Of course such rules are not universally true, but rather have
26 Chapter 1 Introduction
degrees of “support” and “confidence.” Other types of knowledge are represented
by equations relating different variables to each other, or by other mechanisms
for predicting outcomes when the values of some variables are known.
There are a variety of possible types of patterns that may be useful, and
different techniques are used to find different types of patterns. In Chapter 20 we
study a few examples of patterns and see how they may be automatically derived
from a database.
Usually there is a manual component to data mining, consisting of preprocessing data to a form acceptable to the algorithms, and postprocessing of discovered
patterns to find novel ones that could be useful. There may also be more than
one type of pattern that can be discovered from a given database, and manual
interaction may be needed to pick useful types of patterns. For this reason, data
mining is really a semiautomatic process in real life. However, in our description
we concentrate on the automatic aspect of mining.
Businesses have begun to exploit the burgeoning data online to make better
decisions about their activities, such as what items to stock and how best to
target customers to increase sales. Many of their queries are rather complicated,
however, and certain types of information cannot be extracted even by using SQL.
Several techniques and tools are available to help with decision support.
Several tools for data analysis allow analysts to view data in different ways.
Other analysis tools precompute summaries of very large amounts of data, in
order to give fast responses to queries. The SQL standard contains additional
constructs to support data analysis.
Large companies have diverse sources of data that they need to use for making
business decisions. To execute queries efficiently on such diverse data, companies
have built data warehouses. Data warehouses gather data from multiple sources
under a unified schema, at a single site. Thus, they provide the user a single
uniform interface to data.
Textual data, too, has grown explosively. Textual data is unstructured, unlike
the rigidly structured data in relational databases. Querying of unstructured
textual data is referred to as information retrieval. Information retrieval systems
have much in common with database systems—in particular, the storage and
retrieval of data on secondary storage. However, the emphasis in the field of
information systems is different from that in database systems, concentrating on
issues such as querying based on keywords; the relevance of documents to the
query; and the analysis, classification, and indexing of documents. In Chapters 20
and 21, we cover decision support, including online analytical processing, data
mining, data warehousing, and information retrieval.
